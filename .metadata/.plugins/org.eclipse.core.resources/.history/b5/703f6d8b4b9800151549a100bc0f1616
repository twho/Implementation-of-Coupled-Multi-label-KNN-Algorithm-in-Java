package Classifiers;

import java.util.Random;
import java.util.logging.Level;
import java.util.logging.Logger;

import mulan.classifier.MultiLabelOutput;
import mulan.classifier.lazy.MultiLabelKNN;
import mulan.data.MultiLabelInstances;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.TechnicalInformation;
import weka.core.TechnicalInformation.Field;
import weka.core.TechnicalInformation.Type;
import weka.core.Utils;

public class CMLkNN extends MultiLabelKNN {
	private static String ARFF = ".arff";
	private static String XML = ".xml";

	protected double smooth;
	private double[] PriorProbabilities;
	private double[] PriorNProbabilities;
	private double[][] CondProbabilities;
	private double[][] CondNProbabilities;
	// Similarity measurements
	private Double[] RF;
	private double[] vertiSum;
	private Double[][] Freq;
	private double ClsSum[];
	int[] temp_Ci;

	public CMLkNN(int numOfNeighbors, double smooth) {
		super(numOfNeighbors);
		this.smooth = smooth;
	}

	public CMLkNN() {
		super();
		this.smooth = 1.0;
	}

	public String globalInfo() {
		return "Class implementing the CML-kNN (Coupled Multi-Label k Nearest Neighbours) algorithm."
				+ "\n\n"
				+ "For more information, see\n\n"
				+ getTechnicalInformation().toString();
	}

	@Override
	public TechnicalInformation getTechnicalInformation() {
		return null;
	}

	@Override
	protected MultiLabelOutput makePredictionInternal(Instance instance)
			throws Exception {
		double[] confidences = new double[numLabels];
		boolean[] predictions = new boolean[numLabels];

		Instances knn = null;
		try {
			knn = new Instances(
					lnn.kNearestNeighbours(instance, numOfNeighbors));
		} catch (Exception ex) {
			Logger.getLogger(CMLkNN.class.getName())
					.log(Level.SEVERE, null, ex);
		}

		for (int i = 0; i < numLabels; i++) {
			// compute sum of aces in KNN
			int aces = 0; // num of aces in Knn for i
			for (int k = 0; k < numOfNeighbors; k++) {
				double value = Double.parseDouble(train.attribute(
						labelIndices[i]).value(
						(int) knn.instance(k).value(labelIndices[i])));
				if (Utils.eq(value, 1.0)) {
					aces++;
				}
			}
			double Prob_in = PriorProbabilities[i] * CondProbabilities[i][aces];
			double Prob_out = PriorNProbabilities[i]
					* CondNProbabilities[i][aces];
			if (Prob_in > Prob_out) {
				predictions[i] = true;
			} else if (Prob_in < Prob_out) {
				predictions[i] = false;
			} else {
				Random rnd = new Random();
				predictions[i] = (rnd.nextInt(2) == 1) ? true : false;
			}
			confidences[i] = Prob_in / (Prob_in + Prob_out);
		}
		MultiLabelOutput mlo = new MultiLabelOutput(predictions, confidences);
		return mlo;
	}

	@Override
	protected void buildInternal(MultiLabelInstances train) throws Exception {
		super.buildInternal(train);
		PriorProbabilities = new double[numLabels];
		PriorNProbabilities = new double[numLabels];
		CondProbabilities = new double[numLabels][numOfNeighbors + 1];
		CondNProbabilities = new double[numLabels][numOfNeighbors + 1];
		RF = new Double[numLabels + 1]; // RF denotes occurance
		Freq = new Double[numLabels + 1][numLabels + 1]; // co-occurance
		temp_Ci = new int[numLabels + 1];
		ClsSum = new double[numLabels];
		vertiSum = new double[train.getNumInstances()];
		computeRF();
		computeFreq();
		ComputePrior();
		ComputeCond();

		if (getDebug()) {
			System.out.println("Computed Prior Probabilities");
			for (int i = 0; i < numLabels; i++) {
				System.out.println("Label " + (i + 1) + ": "
						+ PriorProbabilities[i]);
			}
			System.out.println("Computed Posterior Probabilities");
			for (int i = 0; i < numLabels; i++) {
				System.out.println("Label " + (i + 1));
				for (int j = 0; j < numOfNeighbors + 1; j++) {
					System.out.println(j + " neighbours: "
							+ CondProbabilities[i][j]);
					System.out.println(j + " neighbours: "
							+ CondNProbabilities[i][j]);
				}
			}
		}
	}

	private void ComputePriorOld() {
		for (int i = 0; i < numLabels; i++) {
			int temp_Ci = 0;
			for (int j = 0; j < train.numInstances(); j++) {
				double value = Double.parseDouble(train.attribute(
						labelIndices[i]).value(
						(int) train.instance(j).value(labelIndices[i])));
				if (Utils.eq(value, 1.0)) {
					temp_Ci++;
				}
			}
			PriorProbabilities[i] = (smooth + temp_Ci)
					/ (smooth * 2 + train.numInstances());
			PriorNProbabilities[i] = 1 - PriorProbabilities[i];
		}
	}

	private void ComputePrior() {
		for (int j = 0; j < train.numInstances(); j++) {
			for (int k = 0; k < numLabels; k++) {
				for (int i = 0; i < numLabels; i++) {
					double value = Double.parseDouble(train.attribute(
							labelIndices[i]).value(
							(int) train.instance(j).value(labelIndices[i])));
					ClsSum[i] += value * Freq[i][k];
				}
			}
		}
		for (int i = 0; i < numLabels; i++) {
			PriorProbabilities[i] = ((smooth + ClsSum[i]))
					/ (smooth * 2 + train.numInstances());
			PriorNProbabilities[i] = 1 - PriorProbabilities[i];
		}
	}

	private void computeRF() {
		for (int i = 0; i < numLabels; i++) {
			for (int j = 0; j < train.numInstances(); j++) {
				double value = Double.parseDouble(train.attribute(
						labelIndices[i]).value(
						(int) train.instance(j).value(labelIndices[i])));
				if (Utils.eq(value, 1.0)) {
					temp_Ci[i]++;
				}
			}
			RF[i] = ((double) temp_Ci[i] / (double) train.numInstances());
		}
	}

	private void computeFreq() {
		double cooccurance = 0;
		for (int i = 0; i < numLabels; i++) {
			for (int k = 0; k < numLabels; k++) {
				double temp_times = 0;
				for (int j = 0; j < train.numInstances(); j++) {
					double valueI = Double.parseDouble(train.attribute(
							labelIndices[i]).value(
							(int) train.instance(j).value(labelIndices[i])));
					double valueK = Double.parseDouble(train.attribute(
							labelIndices[k]).value(
							(int) train.instance(j).value(labelIndices[k])));
					if (valueI * valueK == 1) {
						temp_times++;
					}
					cooccurance = temp_times
							/ ((double) Math.max(temp_Ci[i], temp_Ci[k]));
					Freq[i][k] = cooccurance;
					Freq[k][i] = cooccurance;
				}
			}
		}
	}

	private void ComputeCond() throws Exception {
		int[][] temp_Ci = new int[numLabels][numOfNeighbors + 1];
		int[][] temp_NCi = new int[numLabels][numOfNeighbors + 1];

		for (int i = 0; i < train.numInstances(); i++) {

			Instances knn = new Instances(lnn.kNearestNeighbours(
					train.instance(i), numOfNeighbors));

			// now compute values of temp_Ci and temp_NCi for every class label
			for (int j = 0; j < numLabels; j++) {

				for (int k = 0; k < numOfNeighbors; k++) {
					double value = Double.parseDouble(train.attribute(
							labelIndices[j]).value(
							(int) knn.instance(k).value(labelIndices[j])));
					if (Utils.eq(value, 1.0)) {
						if (ClsSum[j] >= 0.5) {
							temp_Ci[j][k] = k;
						} else {
							temp_NCi[j][k] = k;
						}
					}
				}
			}
		}

		// compute CondProbabilities[i][..] for labels based on temp_Ci[]
		for (int i = 0; i < numLabels; i++) {
			int temp1 = 0;
			int temp2 = 0;
			for (int j = 0; j < numOfNeighbors + 1; j++) {
				temp1 += temp_Ci[i][j];
				temp2 += temp_NCi[i][j];
			}
			for (int j = 0; j < numLabels; j++) {
				CondProbabilities[i][j] = (smooth + temp_Ci[i][j])
						/ (smooth * (numOfNeighbors + 1) + temp1);
				CondNProbabilities[i][j] = (smooth + temp_NCi[i][j])
						/ (smooth * (numOfNeighbors + 1) + temp2);
			}
		}
	}
}
