package Classifiers;

import java.util.Random;
import java.util.logging.Level;
import java.util.logging.Logger;

import mulan.classifier.MultiLabelOutput;
import mulan.classifier.lazy.MultiLabelKNN;
import mulan.data.MultiLabelInstances;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.TechnicalInformation;
import weka.core.TechnicalInformation.Field;
import weka.core.TechnicalInformation.Type;
import weka.core.Utils;

public class CMLkNN extends MultiLabelKNN {

	protected double smooth;
	private double[] PriorProbabilities;
	private double[] PriorNProbabilities;
	private double[][] CondProbabilities;
	private double[][] CondNProbabilities;
	// Similarity measurements
	private Double[] RF;
	private Double[][] freq;
	private double[] clsSum;
	int[] temp_Ci;

	public CMLkNN(int numOfNeighbors, double smooth) {
		super(numOfNeighbors);
		this.smooth = smooth;
	}

	public CMLkNN() {
		super();
		this.smooth = 1.0;
	}

	public String globalInfo() {
		return "Class implementing the CML-kNN (Coupled Multi-Label k Nearest Neighbours) algorithm."
				+ "\n\n"
				+ "For more information, see\n\n"
				+ getTechnicalInformation().toString();
	}

	@Override
	public TechnicalInformation getTechnicalInformation() {
		return null;
	}

	@Override
	protected void buildInternal(MultiLabelInstances train) throws Exception {
		super.buildInternal(train);
		PriorProbabilities = new double[numLabels];
		PriorNProbabilities = new double[numLabels];
		CondProbabilities = new double[numLabels][numOfNeighbors + 1];
		CondNProbabilities = new double[numLabels][numOfNeighbors + 1];
		RF = new Double[numLabels + 1]; // RF denotes occurance
		freq = new Double[numLabels + 1][numLabels + 1]; // co-occurance
		temp_Ci = new int[numLabels + 1];
		clsSum = new double[numLabels];
		computeRF(temp_Ci);
		computeFreq(freq);
		ComputePrior();
		ComputeCond();

		if (getDebug()) {
			System.out.println("Computed Prior Probabilities");
			for (int i = 0; i < numLabels; i++) {
				System.out.println("Label " + (i + 1) + ": "
						+ PriorProbabilities[i]);
			}
			System.out.println("Computed Posterior Probabilities");
			for (int i = 0; i < numLabels; i++) {
				System.out.println("Label " + (i + 1));
				System.out.println(i + " neighbours: " + CondProbabilities[i]);
				System.out.println(i + " neighbours: " + CondNProbabilities[i]);
			}
		}
	}

	private void ComputePriorOld() {
		for (int i = 0; i < numLabels; i++) {
			int temp_Ci = 0;
			for (int j = 0; j < train.numInstances(); j++) {
				double value = Double.parseDouble(train.attribute(
						labelIndices[i]).value(
						(int) train.instance(j).value(labelIndices[i])));
				if (Utils.eq(value, 1.0)) {
					temp_Ci++;
				}
			}
			PriorProbabilities[i] = (smooth + temp_Ci)
					/ (smooth * 2 + train.numInstances());
			PriorNProbabilities[i] = 1 - PriorProbabilities[i];
		}
	}

	private void ComputePrior() {
		for (int j = 0; j < train.numInstances(); j++) {
			for (int k = 0; k < numLabels; k++) {
				for (int i = 0; i < numLabels; i++) {
					double value = Double.parseDouble(train.attribute(
							labelIndices[i]).value(
							(int) train.instance(j).value(labelIndices[i])));
					clsSum[i] += value * freq[i][k];
				}
			}
		}
		for (int i = 0; i < numLabels; i++) {
			PriorProbabilities[i] = ((smooth + clsSum[i]))
					/ (smooth * 2 + train.numInstances());
			PriorNProbabilities[i] = 1 - PriorProbabilities[i];
		}
	}

	private void computeRF(int[] temp_Ci) {
		for (int i = 0; i < numLabels; i++) {
			for (int j = 0; j < train.numInstances(); j++) {
				double value = Double.parseDouble(train.attribute(
						labelIndices[i]).value(
						(int) train.instance(j).value(labelIndices[i])));
				if (Utils.eq(value, 1.0)) {
					temp_Ci[i]++;
				}
			}
			RF[i] = ((double) temp_Ci[i] / (double) train.numInstances());
		}
	}

	private void computeFreq(Double[][] freqArray) {
		double cooccurance = 0;
		for (int i = 0; i < numLabels; i++) {
			for (int k = 0; k < numLabels; k++) {
				double temp_times = 0;
				for (int j = 0; j < train.numInstances(); j++) {
					double valueI = Double.parseDouble(train.attribute(
							labelIndices[i]).value(
							(int) train.instance(j).value(labelIndices[i])));
					double valueK = Double.parseDouble(train.attribute(
							labelIndices[k]).value(
							(int) train.instance(j).value(labelIndices[k])));
					if (valueI * valueK == 1) {
						temp_times++;
					}
					cooccurance = temp_times
							/ ((double) Math.max(temp_Ci[i], temp_Ci[k]));
					freqArray[i][k] = cooccurance;
					freqArray[k][i] = cooccurance;
				}
			}
		}
	}

	private void ComputeCond() throws Exception {
		Double[][] neighborCls = new Double[numLabels][numLabels];
		computeFreq(neighborCls);
		// double[] freqArray = new double[numLabels * numOfNeighbors];
		// double[] freqArrayN = new double[numLabels * numOfNeighbors];

		double[][] newfreqArray = new double[numLabels][numOfNeighbors];
		double[][] newfreqArrayN = new double[numLabels][numOfNeighbors];

		for (int j = 0; j < train.numInstances(); j++) {
			Instances knn = new Instances(lnn.kNearestNeighbours(
					train.instance(j), numOfNeighbors));
			for (int k = 0; k < numOfNeighbors; k++) {
				for (int i = 0; i < numLabels; i++) {
					for (int q = 0; q < numLabels; q++) {
						double value = Double.parseDouble(train.attribute(
								labelIndices[q]).value(
								(int) knn.instance(k).value(labelIndices[q])));
						// System.out.println("neighborCls[i][q]: " +
						// neighborCls[i][q]);
						double x = value * neighborCls[i][q];
						if (x >= .5) {
							newfreqArray[q][k] += value * neighborCls[i][q];

						} else if (x < .5) {
							newfreqArrayN[q][k] += value * neighborCls[i][q];
						}
					}
				}
			}
		}

		for (int i = 0; i < numLabels; i++) {
            int temp1 = 0;
            int temp2 = 0;
            for (int j = 0; j < numOfNeighbors + 1; j++) {
                temp1 += temp_Ci[i][j];
                temp2 += temp_NCi[i][j];
            }
            for (int j = 0; j < numOfNeighbors + 1; j++) {
                CondProbabilities[i][j] = (smooth + temp_Ci[i][j]) / (smooth * (numOfNeighbors + 1) + temp1);
                CondNProbabilities[i][j] = (smooth + temp_NCi[i][j]) / (smooth * (numOfNeighbors + 1) + temp2);
            }
        }
	}

	@Override
	protected MultiLabelOutput makePredictionInternal(Instance instance)
			throws Exception {
		double[] confidences = new double[numLabels];
		boolean[] predictions = new boolean[numLabels];

		Instances knn = null;
		try {
			knn = new Instances(
					lnn.kNearestNeighbours(instance, numOfNeighbors));
		} catch (Exception ex) {
			Logger.getLogger(CMLkNN.class.getName())
					.log(Level.SEVERE, null, ex);
		}

		for (int i = 0; i < numLabels; i++) {
			// compute sum of aces in KNN
			int aces = 0; // num of aces in Knn for i
			for (int k = 0; k < numOfNeighbors; k++) {
				double value = Double.parseDouble(train.attribute(
						labelIndices[i]).value(
						(int) knn.instance(k).value(labelIndices[i])));
				if (Utils.eq(value, 1.0)) {
					aces++;
				}
			}
			double Prob_in = PriorProbabilities[i] * CondProbabilities[i][aces];
			double Prob_out = PriorNProbabilities[i]
					* CondNProbabilities[i][aces];
			if (Prob_in > Prob_out) {
				predictions[i] = true;
			} else if (Prob_in < Prob_out) {
				predictions[i] = false;
			} else {
				Random rnd = new Random();
				predictions[i] = (rnd.nextInt(2) == 1) ? true : false;
			}
			confidences[i] = Prob_in / (Prob_in + Prob_out);
		}
		MultiLabelOutput mlo = new MultiLabelOutput(predictions, confidences);
		return mlo;
	}
}
